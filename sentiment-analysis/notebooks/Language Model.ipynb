{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to export graphs\n",
    "def save_fig(fig_name, tight_layout=True, fig_extension=\"png\", resolution=300, images_path = './images'):\n",
    "    if not os.path.exists(images_path):\n",
    "        os.makedirs(images_path)\n",
    "    path = os.path.join(images_path, fig_name + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_name)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "DATASET_COLUMNS = ['sentiment', 'ids', 'date', 'flag', 'user', 'text']\n",
    "DATASET_ENCODING = 'ISO-8859-1'\n",
    "dataset = pd.read_csv('./data/training.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment         ids                          date      flag  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure Distribution\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# removing the unnecessary columns\n",
    "dataset = dataset[['sentiment', 'text']]\n",
    "dataset['sentiment'] = dataset['sentiment'].replace(4, 1)\n",
    "\n",
    "# plotting the distribution for dataset\n",
    "ax = dataset.groupby('sentiment').count().plot(kind='bar', title='Distribution', legend=False)\n",
    "ax.set_xticklabels(['Negative','Positive'], rotation=0)\n",
    "save_fig(\"Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"training.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing data in lists\n",
    "text, sentiment = list(dataset['text']), list(dataset['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing steps:\n",
    "1. Lower casing\n",
    "2. Replacing URLs: links starting with \"HTTP\", \"HTTPS\", \"WWW\" are replaced by \"URL\"\n",
    "3. Replacing Emojis: mapped against the pre-defined dict\n",
    "4. Replacing Usernames: replace @USERNAME with \"USER\"\n",
    "5. Removing Non-alphabets: replace characters except digits and alphabets with a space\n",
    "6. Removing Consecutive letters: e.g. heyyyy to heyy\n",
    "7. Removing short words: words with length less than 2 are removed\n",
    "8. removing stop words\n",
    "9. Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining dictionary containing all emojis with their meanings.\n",
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
    "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
    "# stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "# English vocabulary\n",
    "WORDS = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(textdata: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Apply filters and transformations on each text record\n",
    "    :param textdata: str\n",
    "    :return: List[str]\n",
    "    \"\"\"\n",
    "    processedText = []\n",
    "\n",
    "\n",
    "    # Defining regex patterns.\n",
    "    urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern = '@[^\\s]+'\n",
    "    alphaPattern = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "\n",
    "    tweet = textdata.lower()\n",
    "\n",
    "    # Replace all URls with 'URL'\n",
    "    tweet = re.sub(urlPattern, ' ', tweet)\n",
    "    # Replace all emojis.\n",
    "    for emoji in EMOJIS.keys():\n",
    "        tweet = tweet.replace(emoji, \"EMOJI\" + EMOJIS[emoji])\n",
    "        # Replace @USERNAME to 'USER'.\n",
    "    tweet = re.sub(userPattern, ' ', tweet)\n",
    "    # Replace all non alphabets.\n",
    "    tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "    # Replace 3 or more consecutive letters by 2 letter.\n",
    "    tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "    # Replace non-english words\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) if w.lower() in WORDS)\n",
    "\n",
    "    tweetwords = ''\n",
    "    for word in tweet.split():\n",
    "        # Checking if the word is a stopword.\n",
    "        if word not in STOPWORDS:\n",
    "            # Replace non-english words\n",
    "            if len(word) > 1:\n",
    "                tweetwords += (word + ' ')\n",
    "    processedText.append(tweetwords)\n",
    "    return processedText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    for tweet in textdata:\n",
    "        tweetwords = preprocess_tweet(tweet)\n",
    "        processedText.append(tweetwords)      \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/joswx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/joswx/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resolve nltk depencies in wordnetlemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Preprocessing complete.\n",
      "Time Taken: 102 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "processedtext = preprocess(text)\n",
    "print(f'Text Preprocessing complete.')\n",
    "print(f'Time Taken: {round(time.time()-t)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split Done\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(processedtext, sentiment, test_size=0.05, random_state=42)\n",
    "print(f'Data Split Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectoriser fitted.\n",
      "No. of feature_words:  50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joswx/Documents/SWE5003/BEAD/sample/bead/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF vectoriser\n",
    "vectoriser = TfidfVectorizer(max_features=50000)\n",
    "vectoriser.fit(X_train)\n",
    "print(f'Vectoriser fitted.')\n",
    "print('No. of feature_words: ', len(vectoriser.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Transformed.\n"
     ]
    }
   ],
   "source": [
    "# Transform the dataset\n",
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)\n",
    "print(f'Data Transformed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def cv_comparison(models, X, y, cv):\n",
    "    cv_accuracies = pd.DataFrame()\n",
    "    accs = []\n",
    "    for model in models:\n",
    "        acc = np.round(cross_val_score(model, X, y, scoring='accuracy', cv = cv), 4)\n",
    "        accs.append(acc)\n",
    "        acc_avg = round(acc.mean(), 4)\n",
    "        cv_accuracies[str(model)] = [acc_avg]\n",
    "    cv_accuracies.index = ['Accuracy']\n",
    "    return cv_accuracies, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "BNBmodel = BernoulliNB(alpha=2)\n",
    "SVCmodel = LinearSVC()\n",
    "LRmodel = LogisticRegression(C = 2, max_iter = 1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [BNBmodel, SVCmodel, LRmodel]\n",
    "comp, accs = cv_comparison(models, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BernoulliNB(alpha=2)</th>\n",
       "      <th>LinearSVC()</th>\n",
       "      <th>LogisticRegression(C=2, max_iter=1000, n_jobs=-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.7953</td>\n",
       "      <td>0.7994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BernoulliNB(alpha=2)  LinearSVC()  \\\n",
       "Accuracy                0.7781       0.7953   \n",
       "\n",
       "          LogisticRegression(C=2, max_iter=1000, n_jobs=-1)  \n",
       "Accuracy                                             0.7994  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.779 , 0.778 , 0.7789, 0.7796, 0.7783, 0.7757, 0.7759, 0.7785,\n",
       "        0.7798, 0.7778]),\n",
       " array([0.7958, 0.7953, 0.7958, 0.7958, 0.7955, 0.7953, 0.7931, 0.7955,\n",
       "        0.7964, 0.7948]),\n",
       " array([0.7991, 0.7995, 0.8   , 0.7999, 0.7991, 0.7991, 0.7976, 0.8   ,\n",
       "        0.8   , 0.7994])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.800025 using {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.792738 (0.001012) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.797562 (0.001000) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.792742 (0.001019) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.796158 (0.001100) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.797995 (0.001043) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.796161 (0.001099) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.800025 (0.001129) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.799759 (0.001058) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.800024 (0.001125) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.795923 (0.001029) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.795918 (0.001029) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.795926 (0.001028) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.779456 (0.001032) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.779458 (0.001028) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.779455 (0.001027) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for log regression model\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "grid = dict(solver = solvers, penalty = penalty, C = c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "file = open('./model/vectoriser-ngram-(1,1).pkl','wb')\n",
    "joblib.dump(vectoriser, file)\n",
    "file.close()\n",
    "\n",
    "file = open('./model/Sentiment-svc.pkl', 'wb')\n",
    "joblib.dump(SVCmodel, file)\n",
    "file.close()\n",
    "\n",
    "file = open('./model/Sentiment-LR.pkl','wb')\n",
    "joblib.dump(LRmodel, file)\n",
    "file.close()\n",
    "\n",
    "file = open('./model/Sentiment-BNB.pkl','wb')\n",
    "joblib.dump(BNBmodel, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample use case\n",
    "def load_models():\n",
    "    \n",
    "    # Load the vectoriser.\n",
    "    file = open('./model/vectoriser-ngram-(1,2).pkl', 'rb')\n",
    "    vectoriser = joblib.load(file)\n",
    "    file.close()\n",
    "    # Load the LR Model.\n",
    "    file = open('./model/Sentiment-LRv1.pkl', 'rb')\n",
    "    LRmodel = joblib.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return vectoriser, LRmodel\n",
    "\n",
    "def predict(vectoriser, model, text):\n",
    "    # Predict the sentiment\n",
    "    textdata = vectoriser.transform(preprocess(text))\n",
    "    sentiment = model.predict(textdata)\n",
    "    \n",
    "    # Make a list of text with sentiment.\n",
    "    data = []\n",
    "    for text, pred in zip(text, sentiment):\n",
    "        data.append((text,pred))\n",
    "        \n",
    "    # Convert the list into a Pandas DataFrame.\n",
    "    df = pd.DataFrame(data, columns = ['text','sentiment'])\n",
    "    df = df.replace([0,1], [\"Negative\",\"Positive\"])\n",
    "    return df\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # Loading the models.\n",
    "    #vectoriser, LRmodel = load_models()\n",
    "    \n",
    "    # Text to classify should be in a list.\n",
    "    text = [\"BTC to the moon\"]\n",
    "    \n",
    "    df = predict(vectoriser, LRmodel, text)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bead",
   "language": "python",
   "name": "bead"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
